{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Create Import file (try, except)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a class to grade (i.e. class1 for class1)\n",
      "Successfully opened class3.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter a class to grade (i.e. class1 for class1)\")\n",
    "name = input()\n",
    "try:\n",
    "    with open(name+'.txt','r') as gs:\n",
    "        grades = gs.readlines()\n",
    "        print(\"Successfully opened\", name+'.txt')\n",
    "        #print(grades)\n",
    "except IOError:\n",
    "        print(\"File not accessible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Inspect Value (check if has 26 values, print invalid, report)\n",
    "\n",
    "for loop to check if has 26 values, if not, print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid lines of data: 100\n",
      "Total invalid lines of data: 0\n"
     ]
    }
   ],
   "source": [
    "#Make a copy dataframe to check how many invalid lines of data have been removed\n",
    "new_grades_df = grades.copy()\n",
    "#Loop over the 'grades' data, check if length of id is not 9 and the elements of each iteration is not 26. If yes, print then remove.\n",
    "for grade in new_grades_df: \n",
    "            value = grade.split(\",\")\n",
    "            length = len(value)\n",
    "            if length != 26:\n",
    "                corrupted_ID = value[0]\n",
    "                print(\"Invalid line of data:\", corrupted_ID, \" does not contain exactly 26 values:\")\n",
    "                print(grade)\n",
    "                new_grades_df.remove(grade)\n",
    "            id = value[0]\n",
    "            id_length = len(id)\n",
    "            if id_length != 9:\n",
    "                corrupted_ID = value[0]\n",
    "                print(\"Invalid line of data:\", corrupted_ID, \" is invalid\")\n",
    "                new_grades_df.remove(grade)\n",
    "values_false = len(grades) - len(new_grades_df)\n",
    "print(\"Total valid lines of data:\", len(new_grades_df))\n",
    "print(\"Total invalid lines of data:\", values_false)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Calculate Exam Test:\n",
    "How many high score \n",
    "average score\n",
    "highest score\n",
    "lowest score \n",
    "range of score(highest minus lowest) \n",
    "question most people skip(question num - how many)\n",
    "question most answer incorrectly(question num - how many)\n",
    "\n",
    "----------\n",
    "Student of highscore \n",
    "Print result out\n",
    "!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (average) score: 76.24\n",
      "Highest score: 96\n",
      "Lowest score: 56\n",
      "Range of scores: 40\n",
      "Median score: 76.24\n",
      "Question that most people answer incorrectly: 17\n",
      "Question 17 is answered incorrectly 17 times - 0.17\n",
      "----------------------\n",
      "Question that most people skip: 3\n",
      "Question 3 is skipped 15 times - 0.15\n"
     ]
    }
   ],
   "source": [
    "answer_keys = \"B,A,D,D,C,B,D,A,C,C,D,B,A,B,A,C,B,D,A,C,A,A,B,D,D\"\n",
    "answer_key = answer_keys.split(\",\")\n",
    "answer_key_table = pd.DataFrame(answer_key)\n",
    "answers_checked = []\n",
    "score_list = []\n",
    "highScore_loop = []\n",
    "for grade in new_grades_df:\n",
    "        value = grade.split(\",\")\n",
    "        id = value[0]\n",
    "        #Create \"answer_table\" data frame from the grades dataframe and remove student id from data frame\n",
    "        answer_table = pd.DataFrame(value)\n",
    "        answer_table = answer_table.iloc[1: , :]\n",
    "        answer_table = answer_table.reset_index(drop=True)\n",
    "        #Remove \\n from value\n",
    "        cVal = answer_table.iloc[24][0]\n",
    "        cValSplit = cVal.split(\"\\n\")\n",
    "        c = cValSplit[0]\n",
    "        answer_table = answer_table.replace([cVal],c)\n",
    "        #Compare student answers with answer keys to a new column called \"checkAnswer\", return True if correct, return the correct answer if false and \"\" if blank\n",
    "        conditions  = [answer_table[0] == answer_key_table[0], answer_table[0] == \"\" , answer_table[0] != answer_key_table[0]]\n",
    "        choices     = [ \"True\", '',answer_key_table[0]]\n",
    "        answer_table[\"checkAnswer\"] = np.select(conditions, choices, default=np.nan)\n",
    "        #Calculate the quantity of correct, false and blank answers.\n",
    "        num_correct = (answer_table['checkAnswer']=='True').sum()\n",
    "        num_blank = (answer_table['checkAnswer']=='').sum()\n",
    "        num_incorrect = len(answer_table[answer_table['checkAnswer'].map(lambda x: x !='True' and x !='')])\n",
    "        #Calculate the score\n",
    "        score = num_correct*4 + num_incorrect*(-1)\n",
    "        #Make a new dataframe with 2 columns, id and score, then export the dataframe outside loop\n",
    "        score_df = pd.DataFrame({'id': [id], 'score': [score]})\n",
    "        score_list.append(score_df)\n",
    "        #Get the list of student with high score to an instanced dataframe\n",
    "        #highScore= sum(score_df[score_df['score'] > 80])\n",
    "\n",
    "        #highScore_loop.append(highScore_list)\n",
    "        #print(score_df)\n",
    "    \n",
    "\n",
    "\n",
    "        answers_checked.append(answer_table)\n",
    "#print(highScore_loop)\n",
    "score_pd = pd.concat(score_list)\n",
    "#print(score_pd)\n",
    "# Calculate max,min, mean, range of score, and median\n",
    "mean = round(score_pd['score'].mean(),2)\n",
    "max = score_pd['score'].max()\n",
    "min = score_pd['score'].min()\n",
    "RoS = max - min\n",
    "num_students = score_pd['id'].nunique()\n",
    "totalScore = score_pd['score'].sum()\n",
    "med = round(totalScore/num_students,2)\n",
    "print(\"Mean (average) score:\", mean)\n",
    "print(\"Highest score:\", max)\n",
    "print(\"Lowest score:\", min)\n",
    "print(\"Range of scores:\", RoS)\n",
    "print(\"Median score:\", med)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "answer_pd = pd.concat(answers_checked)\n",
    "answer_pd.columns = ['studentAnswer', 'checkAnswer']\n",
    "answer_pd['question'] = answer_pd.index\n",
    "\n",
    "\n",
    "#Find out the question students most answer incorrectly and how many time the question is incorrect.\n",
    "answers_incorrect_pd = answer_pd[answer_pd['checkAnswer'] != \"True\"]\n",
    "answers_incorrect_pd = answers_incorrect_pd[answers_incorrect_pd['studentAnswer'] != \"\"]\n",
    "answer_incorrect_count = answers_incorrect_pd.groupby('question')['question'].count()\n",
    "question_most_incorrect = answer_incorrect_count.idxmax()\n",
    "num_answer_incorrect = answer_incorrect_count.max()\n",
    "ratio_incorrect = round(num_answer_incorrect / num_students,2)\n",
    "print(\"Question that most people answer incorrectly:\", question_most_incorrect)\n",
    "print(\"Question\", question_most_incorrect, \"is answered incorrectly\", num_answer_incorrect, \"times\",\"-\",ratio_incorrect)\n",
    "print(\"----------------------\")\n",
    "\n",
    "#Find out the question students most leave blank and how many time the question is leave blank.\n",
    "answers_blank_pd = answer_pd[answer_pd['studentAnswer'] == \"\"]\n",
    "answers_blank_count = answers_blank_pd.groupby('question')['question'].count()\n",
    "question_most_leave_blank = answers_blank_count.idxmax()\n",
    "num_answer_blank = answers_blank_count.max()\n",
    "ratio_blank = round(num_answer_blank/ num_students,2)\n",
    "print(\"Question that most people skip:\", question_most_leave_blank)\n",
    "print(\"Question\", question_most_leave_blank, \"is skipped\", num_answer_blank, \"times\",\"-\",ratio_blank)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Export text file: \n",
    "as xxx_grades.txt\n",
    "list as 'id', 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
