{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Create Import file (try, except)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a class to grade (i.e. class1 for class1)\n",
      "Successfully opened class2.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter a class to grade (i.e. class1 for class1)\")\n",
    "name = input()\n",
    "try:\n",
    "    with open(name+'.txt','r') as gs:\n",
    "        grades = gs.readlines()\n",
    "        print(\"Successfully opened\", name+'.txt')\n",
    "        #print(grades)\n",
    "except IOError:\n",
    "        print(\"File not accessible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Inspect Value (check if has 26 values, print invalid, report)\n",
    "\n",
    "for loop to check if has 26 values, if not, print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid line of data: N00000023  does not contain exactly 26 values:\n",
      "N00000023,,A,D,D,C,B,D,A,C,C,,C,,B,A,C,B,D,A,C,A,A\n",
      "\n",
      "Invalid line of data: N0000002  is invalid\n",
      "N0000002,B,A,D,D,C,B,D,A,C,D,D,D,A,,A,C,D,,A,C,A,A,B,D,D\n",
      "\n",
      "Invalid line of data: NA0000027  is invalid\n",
      "NA0000027,B,A,D,D,,B,,A,C,B,D,B,A,,A,C,B,D,A,,A,A,B,D,D\n",
      "\n",
      "Invalid line of data: N00000035  does not contain exactly 26 values:\n",
      "N00000035,B,A,D,D,B,B,,A,C,,D,B,A,B,A,A,B,D,A,C,A,C,B,D,D,A,A\n",
      "\n",
      "Total valid lines of data: 21\n",
      "Total invalid lines of data: 4\n"
     ]
    }
   ],
   "source": [
    "#Make a copy dataframe to check how many invalid lines of data have been removed\n",
    "new_grades_df = grades.copy()\n",
    "#Loop over the 'grades' data, check if length of id is not 9 and the elements of each iteration is not 26. If yes, print then remove.\n",
    "for grade in new_grades_df: \n",
    "            value = grade.split(\",\")\n",
    "            length = len(value)\n",
    "            if length != 26:\n",
    "                corrupted_ID = value[0]\n",
    "                print(\"Invalid line of data:\", corrupted_ID, \" does not contain exactly 26 values:\")\n",
    "                print(grade)\n",
    "                new_grades_df.remove(grade)\n",
    "            id = value[0]\n",
    "            id_length = len(id)\n",
    "            if id_length != 9:\n",
    "                corrupted_ID = value[0]\n",
    "                print(\"Invalid line of data:\", corrupted_ID, \" is invalid\")\n",
    "                print(grade)\n",
    "                new_grades_df.remove(grade)\n",
    "            id_chars= list(id)\n",
    "            id_chars.pop(0)\n",
    "            for char in id_chars:\n",
    "                    if char.isnumeric() ==0:\n",
    "                        print(\"Invalid line of data:\", id, \" is invalid\")\n",
    "                        print(grade)\n",
    "                        new_grades_df.remove(grade)\n",
    "\n",
    "                \n",
    "values_false = len(grades) - len(new_grades_df)\n",
    "num_students = len(new_grades_df)\n",
    "print(\"Total valid lines of data:\", num_students)\n",
    "print(\"Total invalid lines of data:\", values_false)\n",
    "\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isnumeric.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Calculate Exam Test:\n",
    "How many high score \n",
    "average score\n",
    "highest score\n",
    "lowest score \n",
    "range of score(highest minus lowest) \n",
    "question most people skip(question num - how many)\n",
    "question most answer incorrectly(question num - how many)\n",
    "\n",
    "----------\n",
    "Student of highscore \n",
    "Print result out\n",
    "!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total student of high scores: 7\n",
      "Mean (average) score: 78.0\n",
      "Highest score: 100\n",
      "Lowest score: 66\n",
      "Range of scores: 34\n",
      "Median score: 76.0\n",
      "Question that most people answer incorrectly: 17\n",
      "Question 17 is answered incorrectly 5 times - 0.24\n",
      "----------------------\n",
      "Question that most people skip: 21\n",
      "Question 21 is skipped 6 times - 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinh\\AppData\\Local\\Temp\\ipykernel_9392\\3887153929.py:45: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  med_row = score_pd_sorted.median()\n"
     ]
    }
   ],
   "source": [
    "answer_keys = \"B,A,D,D,C,B,D,A,C,C,D,B,A,B,A,C,B,D,A,C,A,A,B,D,D\"\n",
    "answer_key = answer_keys.split(\",\")\n",
    "answer_key_table = pd.DataFrame(answer_key)\n",
    "answers_checked = []\n",
    "score_list = []\n",
    "highScore_loop = []\n",
    "for grade in new_grades_df:\n",
    "        value = grade.split(\",\")\n",
    "        id = value[0]\n",
    "        #Create \"answer_table\" data frame from the grades dataframe and remove student id from data frame\n",
    "        answer_table = pd.DataFrame(value)\n",
    "        answer_table = answer_table.iloc[1: , :]\n",
    "        answer_table = answer_table.reset_index(drop=True)\n",
    "        #Remove \\n from value\n",
    "        cVal = answer_table.iloc[24][0]\n",
    "        cValSplit = cVal.split(\"\\n\")\n",
    "        c = cValSplit[0]\n",
    "        answer_table = answer_table.replace([cVal],c)\n",
    "        #Compare student answers with answer keys to a new column called \"checkAnswer\", return True if correct, return the correct answer if false and \"\" if blank\n",
    "        conditions  = [answer_table[0] == answer_key_table[0], answer_table[0] == \"\" , answer_table[0] != answer_key_table[0]]\n",
    "        choices     = [ \"True\", '',answer_key_table[0]]\n",
    "        answer_table[\"checkAnswer\"] = np.select(conditions, choices, default=np.nan)\n",
    "        #Calculate the quantity of correct, false and blank answers.\n",
    "        num_correct = (answer_table['checkAnswer']=='True').sum()\n",
    "        num_blank = (answer_table['checkAnswer']=='').sum()\n",
    "        num_incorrect = len(answer_table[answer_table['checkAnswer'].map(lambda x: x !='True' and x !='')])\n",
    "        #Calculate the score\n",
    "        score = num_correct*4 + num_incorrect*(-1)\n",
    "        #Make a new dataframe with 2 columns, id and score, then export the dataframe outside loop\n",
    "        score_pd = pd.DataFrame({'id': [id], 'score': [score]})\n",
    "        score_list.append(score_pd)\n",
    "        answers_checked.append(answer_table)\n",
    "score_pd = pd.concat(score_list)\n",
    "# Get the number of students with high score(>80)\n",
    "high_score_pd = score_pd[score_pd['score'] > 80]\n",
    "high_score_count = len(high_score_pd)\n",
    "print(\"Total student of high scores:\",high_score_count)\n",
    "# Calculate max,min, mean, range of score, and median\n",
    "mean = round(score_pd['score'].mean(),2)\n",
    "max = score_pd['score'].max()\n",
    "min = score_pd['score'].min()\n",
    "RoS = max - min\n",
    "score_pd_sorted = score_pd.sort_values(by=['score'])\n",
    "score_pd_sorted = score_pd_sorted.reset_index(drop=True)\n",
    "med_row = score_pd_sorted.median()\n",
    "med= med_row[0]\n",
    "print(\"Mean (average) score:\", mean)\n",
    "print(\"Highest score:\", max)\n",
    "print(\"Lowest score:\", min)\n",
    "print(\"Range of scores:\", RoS)\n",
    "print(\"Median score:\", med)\n",
    "answer_pd = pd.concat(answers_checked)\n",
    "answer_pd.columns = ['studentAnswer', 'checkAnswer']\n",
    "answer_pd['question'] = answer_pd.index\n",
    "\n",
    "\n",
    "#Find out the question students most answer incorrectly and how many time the question is incorrect.\n",
    "answers_incorrect_pd = answer_pd[answer_pd['checkAnswer'] != \"True\"]\n",
    "answers_incorrect_pd = answers_incorrect_pd[answers_incorrect_pd['studentAnswer'] != \"\"]\n",
    "answer_incorrect_count = answers_incorrect_pd.groupby('question')['question'].count()\n",
    "question_most_incorrect = answer_incorrect_count.idxmax()\n",
    "num_answer_incorrect = answer_incorrect_count.max()\n",
    "ratio_incorrect = round(num_answer_incorrect / num_students,2)\n",
    "print(\"Question that most people answer incorrectly:\", question_most_incorrect)\n",
    "print(\"Question\", question_most_incorrect, \"is answered incorrectly\", num_answer_incorrect, \"times\",\"-\",ratio_incorrect)\n",
    "print(\"----------------------\")\n",
    "\n",
    "#Find out the question students most leave blank and how many time the question is leave blank.\n",
    "answers_blank_pd = answer_pd[answer_pd['studentAnswer'] == \"\"]\n",
    "answers_blank_count = answers_blank_pd.groupby('question')['question'].count()\n",
    "question_most_leave_blank = answers_blank_count.idxmax()\n",
    "num_answer_blank = answers_blank_count.max()\n",
    "ratio_blank = round(num_answer_blank/ num_students,2)\n",
    "print(\"Question that most people skip:\", question_most_leave_blank)\n",
    "print(\"Question\", question_most_leave_blank, \"is skipped\", num_answer_blank, \"times\",\"-\",ratio_blank)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Export text file: \n",
    "as xxx_grades.txt\n",
    "list as 'id', 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  with open(name+\"_grades'.txt','w') as gs:\n",
    "#         grades = gs.readlines()\n",
    "#         print(\"Successfully opened\", name+'.txt')\n",
    "s = score_pd.to_string(header=False,index=False,index_names=False).split('\\n')\n",
    "with open('test.txt', 'w') as f:\n",
    "    for x in s:\n",
    "        line = x.split(None,2)\n",
    "        f.write(', '.join(line)+ '\\n')\n",
    "        #print(line)\n",
    "        \n",
    "#print(s)\n",
    "# for i in range(len(score_pd)):\n",
    "#     print(score_pd.loc[i, \"id\"], score_pd.loc[i, \"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "381157050c8046b41869433d9fd733424c97d932ef4e5a287b77faf68dffd6a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
