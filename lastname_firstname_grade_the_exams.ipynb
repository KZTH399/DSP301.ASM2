{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Create Import file (try, except)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a class to grade (i.e. class1 for class1)\n",
      "Successfully opened class5.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter a class to grade (i.e. class1 for class1)\")\n",
    "name = input()\n",
    "try:\n",
    "    with open(name+'.txt','r') as gs:\n",
    "        grades = gs.readlines()\n",
    "        print(\"Successfully opened\", name+'.txt')\n",
    "        #print(grades)\n",
    "except IOError:\n",
    "        print(\"File not accessible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Inspect Value (check if has 26 values, print invalid, report)\n",
    "\n",
    "for loop to check if has 26 values, if not, print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid lines of data: 1000\n",
      "Total invalid lines of data: 0\n"
     ]
    }
   ],
   "source": [
    "#Make a copy dataframe to check how many invalid lines of data have been removed\n",
    "new_grades_df = grades.copy()\n",
    "#Loop over the 'grades' data, check if length of id is not 9 and the elements of each iteration is not 26. If yes, print then remove.\n",
    "for grade in new_grades_df: \n",
    "            value = grade.split(\",\")\n",
    "            length = len(value)\n",
    "            if length != 26:\n",
    "                corrupted_ID = value[0]\n",
    "                print(\"Invalid line of data:\", corrupted_ID, \" does not contain exactly 26 values:\")\n",
    "                print(grade)\n",
    "                new_grades_df.remove(grade)\n",
    "            id = value[0]\n",
    "            id_length = len(id)\n",
    "            if id_length != 9:\n",
    "                corrupted_ID = value[0]\n",
    "                print(\"Invalid line of data:\", corrupted_ID, \" is invalid\")\n",
    "                new_grades_df.remove(grade)\n",
    "values_false = len(grades) - len(new_grades_df)\n",
    "print(\"Total valid lines of data:\", len(new_grades_df))\n",
    "print(\"Total invalid lines of data:\", values_false)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Calculate Exam Test:\n",
    "How many high score \n",
    "average score\n",
    "highest score\n",
    "lowest score \n",
    "range of score(highest minus lowest) \n",
    "question most people skip(question num - how many)\n",
    "question most answer incorrectly(question num - how many)\n",
    "\n",
    "----------\n",
    "Student of highscore \n",
    "Print score value\n",
    "Get ratio of skip, incorrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  score\n",
      "0   N00000641     92\n",
      "0   N00000642     61\n",
      "0   N00000643     75\n",
      "0   N00000644     82\n",
      "0   N00000645     64\n",
      "..        ...    ...\n",
      "0   N00001636     69\n",
      "0   N00001637     64\n",
      "0   N00001638     71\n",
      "0   N00001639     82\n",
      "0   N00001640     82\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "75.6\n",
      "Question that most people answer incorrectly: 11\n",
      "Question 11 is answered incorrectly 130 times\n",
      "----------------------\n",
      "Question that most people skip: 5\n",
      "Question 5 is skipped 117 times\n"
     ]
    }
   ],
   "source": [
    "answer_keys = \"B,A,D,D,C,B,D,A,C,C,D,B,A,B,A,C,B,D,A,C,A,A,B,D,D\"\n",
    "answer_key = answer_keys.split(\",\")\n",
    "answer_key_table = pd.DataFrame(answer_key)\n",
    "answers_checked = []\n",
    "score_list = []\n",
    "highScore_loop = []\n",
    "for grade in new_grades_df:\n",
    "        value = grade.split(\",\")\n",
    "        id = value[0]\n",
    "        #Create \"answer_table\" data frame from the grades dataframe and remove student id from data frame\n",
    "        answer_table = pd.DataFrame(value)\n",
    "        answer_table = answer_table.iloc[1: , :]\n",
    "        answer_table = answer_table.reset_index(drop=True)\n",
    "        #Remove \\n from value\n",
    "        cVal = answer_table.iloc[24][0]\n",
    "        cValSplit = cVal.split(\"\\n\")\n",
    "        c = cValSplit[0]\n",
    "        answer_table = answer_table.replace([cVal],c)\n",
    "        #Compare student answers with answer keys to a new column called \"checkAnswer\", return True if correct, return the correct answer if false and \"\" if blank\n",
    "        conditions  = [answer_table[0] == answer_key_table[0], answer_table[0] == \"\" , answer_table[0] != answer_key_table[0]]\n",
    "        choices     = [ \"True\", '',answer_key_table[0]]\n",
    "        answer_table[\"checkAnswer\"] = np.select(conditions, choices, default=np.nan)\n",
    "        #Calculate the quantity of correct, false and blank answers.\n",
    "        num_correct = (answer_table['checkAnswer']=='True').sum()\n",
    "        num_blank = (answer_table['checkAnswer']=='').sum()\n",
    "        num_incorrect = len(answer_table[answer_table['checkAnswer'].map(lambda x: x !='True' and x !='')])\n",
    "        #Calculate the score\n",
    "        score = num_correct*4 + num_incorrect*(-1)\n",
    "        #Make a new dataframe with 2 columns, id and score, then export the dataframe outside loop\n",
    "        score_df = pd.DataFrame({'id': [id], 'score': [score]})\n",
    "        score_list.append(score_df)\n",
    "        #Get the list of student with high score to an instanced dataframe\n",
    "        #highScore= sum(score_df[score_df['score'] > 80])\n",
    "\n",
    "        highScore_loop.append(highScore_list)\n",
    "        #print(score_df)\n",
    "    \n",
    "\n",
    "\n",
    "        answers_checked.append(answer_table)\n",
    "#print(highScore_loop)\n",
    "score_pd = pd.concat(score_list)\n",
    "print(score_pd)\n",
    "# Calculate max,min, mean, range of score, and median\n",
    "mean = score_pd['score'].mean()\n",
    "max = score_pd['score'].max()\n",
    "min = score_pd['score'].min()\n",
    "RoS = max - min\n",
    "num_students = score_pd['id'].nunique()\n",
    "totalScore = score_pd['score'].sum()\n",
    "med = round(totalScore/num_students,2)\n",
    "print(med)\n",
    "#sum score column and divide with num_students -> average\n",
    "\n",
    "\n",
    "answer_pd = pd.concat(answers_checked)\n",
    "answer_pd.columns = ['studentAnswer', 'checkAnswer']\n",
    "answer_pd['question'] = answer_pd.index\n",
    "\n",
    "#Find out the question students most answer incorrectly and how many time the question is incorrect.\n",
    "answers_incorrect_pd = answer_pd[answer_pd['checkAnswer'] != \"True\"]\n",
    "answers_incorrect_pd = answers_incorrect_pd[answers_incorrect_pd['studentAnswer'] != \"\"]\n",
    "answer_incorrect_count = answers_incorrect_pd.groupby('question')['question'].count()\n",
    "question_most_incorrect = answer_incorrect_count.idxmax()\n",
    "num_answer_inccorect = answer_incorrect_count.max()\n",
    "print(\"Question that most people answer incorrectly:\", question_most_incorrect)\n",
    "print(\"Question\", question_most_incorrect, \"is answered incorrectly\", num_answer_inccorect, \"times\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "#Find out the question students most leave blank and how many time the question is leave blank.\n",
    "answers_blank_pd = answer_pd[answer_pd['studentAnswer'] == \"\"]\n",
    "answers_blank_count = answers_blank_pd.groupby('question')['question'].count()\n",
    "question_most_leave_blank = answers_blank_count.idxmax()\n",
    "num_answer_blank = answers_blank_count.max()\n",
    "print(\"Question that most people skip:\", question_most_leave_blank)\n",
    "print(\"Question\", question_most_leave_blank, \"is skipped\", num_answer_blank, \"times\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Export text file: \n",
    "as xxx_grades.txt\n",
    "list as 'id', 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "381157050c8046b41869433d9fd733424c97d932ef4e5a287b77faf68dffd6a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
